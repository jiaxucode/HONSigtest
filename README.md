# HONSigtest

**HONSigtest** is a Python project for significant dependencies with variable orders mining (**SDVOM**) method, which could capture significant dependencies with variable orders in sequential datasets. 
It provides a complete pipelineâ€”from trajectory simulation and rule extraction to statistical significance testing â€” applicable to domains such as transportation flows, communication networks, and web clickstreams.

---

## ðŸ“ Project Structure

```
HONSigtest/
â”‚
â”œâ”€â”€ main.py                             # Main entry script for running significance test workflows
â”‚
â”œâ”€â”€ dependencies/                       # Core modules for dependency rule extraction and preprocessing
â”‚   â”œâ”€â”€ different_orders_rules_count.py      # Categorizes and counts rules of different orders
â”‚   â”œâ”€â”€ ExtractVariableOrderRules.py         # Core algorithm for extracting variable-order dependency rules
â”‚   â”œâ”€â”€ find_real_second_dependencies.py     # Identifies and validates second-order dependencies
â”‚   â”œâ”€â”€ input_output_file.py                 # Reads and preprocesses sequential trajectory data
â”‚   â”œâ”€â”€ rules_related_functions.py           # Helper functions for rule extraction and manipulation
â”‚   â””â”€â”€ variables_to_pickleFile.py           # Utility functions for variable serialization (pickle)
â”‚
â”œâ”€â”€ significancetest/                   # Statistical significance testing modules
â”‚   â””â”€â”€ ExtractElementsDistributions.py     # Performs distribution analysis and confidence interval testing
â”‚
â”œâ”€â”€ simulation_test/                    # Simulation and synthetic trajectory generation
â”‚   â”œâ”€â”€ build-simulation_grid100.py         # Builds higher-order simulation datasets
â”‚   â”œâ”€â”€ CalculateRulesDistributionOfSimulationData-grid100.py  # Computes rule distributions from simulated data
â”‚   â””â”€â”€ webclickstream_tools_grid100.py    # Simulates multi-order clickstream trajectories based on transition matrices
â”‚
â””â”€â”€ .idea/                              # PyCharm IDE configuration files (not required for execution)
```


---

## ðŸ§© Key Components

### 1. **Trajectory Simulation (`simulation_test/`)**
Simulates clickstream or trajectory data using multi-order Markov chains.  
- Supports orders from 1st to 4th.  
- Generates synthetic trajectories for validation of dependencies with variable orders.  
- Based on transition probability matrices stored as `.npy` or `.pickle` files.

### 2. **Variable-Order Rule Extraction (`dependencies/`)**
Implements recursive algorithms for mining  with variable-order rules.  
- Counts co-occurrence frequencies and builds transition probability distributions.  
- Automatically extends lower-order nodes to higher orders.  
- Supports minimum support threshold (`MinSupport`) for rule pruning.

### 3. **Significance Testing (`significancetest/`)**
Performs statistical significant tests for variable-order rules.
- Computes means, variances, Z-scores, and confidence intervals (99%).  
- Identifies statistically significant dependencies beyond random fluctuations.  
- Export of results as `.csv`.

---

## âš™ï¸ Environment Requirements

```bash
Python >= 3.7
numpy
pandas
scipy
statistics
matplotlib
```
---

## ðŸš€ Usage

### 1ï¸âƒ£ Run the Main Workflow

Execute the complete multi-order significance test process:

```bash
python main.py
```

By default, the script performs 2ndâ€“4th order significance tests and generates result files:

```
2nd_order_SignificantRules_mo4_99%CI.csv
3rd_order_SignificantRules_mo4_99%CI.csv
4th_order_SignificantRules_mo4_99%CI.csv
```

---

### 2ï¸âƒ£ Optional Environment Variables

You can customize the number of iterations, trajectory count, and minimum support threshold when running the main script:

```bash
SIGTEST_ITER=30 TRAJ_NUM=1000 MIN_SUPPORT=5 N_PROCESSES=8 python main.py
```

| Environment Variable | Description | Default |
|----------------------|-------------|----------|
| **`SIGTEST_ITER`** | Number of Monte Carlo iterations for significance testing | `30` |
| **`TRAJ_NUM`** | Number of simulated trajectories generated per order | `1000` |
| **`MIN_SUPPORT`** | Minimum frequency threshold for rule extraction | `5` |
| **`N_PROCESSES`** | Number of parallel processes for computation | `8` |

ðŸ’¡ *Tip:* Increasing `SIGTEST_ITER` improves statistical robustness, while higher `TRAJ_NUM` increases accuracy but also computation time.

---

### 3ï¸âƒ£ Output Files

After running `main.py`, all results of significant dependencies with variable order are automatically saved in:

```
simulation_test/data/rules/20231114/
```

Each file contains the statistically significant dependencies identified at the corresponding order:

| File Name | Description |
|------------|-------------|
| `2nd_order_SignificantRules_mo4_99%CI.csv` | Significant second-order dependencies at the 99% confidence interval |
| `3rd_order_SignificantRules_mo4_99%CI.csv` | Significant third-order dependencies at the 99% confidence interval |
| `4th_order_SignificantRules_mo4_99%CI.csv` | Significant fourth-order dependencies at the 99% confidence interval |

#### ðŸ“‚ Example Directory Structure

```
simulation_test/
â””â”€â”€ data/
    â””â”€â”€ rules/
        â””â”€â”€ 20231114/
            â”œâ”€â”€ 2nd_order_SignificantRules_mo4_99%CI.csv
            â”œâ”€â”€ 3rd_order_SignificantRules_mo4_99%CI.csv
            â””â”€â”€ 4th_order_SignificantRules_mo4_99%CI.csv
```

#### ðŸ“Š CSV File Structure

Each result file (`*_SignificantRules_mo4_99%CI.csv`) contains the following columns:

| Column Name | Meaning |
|--------------|----------|
| **`Rule`** | The identified dependency pattern (e.g., `A â†’ B â†’ C`) |
| **`Observed_Probability`** | Empirical transition probability of the dependency |

---

### 4ï¸âƒ£ Example Workflow Summary

1. Load transition probability matrices (`1st-order`â€“`4th-order`).  
2. Generate synthetic trajectories using `webclickstream_tools_grid100.py`.  
3. Extract variable-order dependency rules via `ExtractVariableOrderRules.py`.  
4. Perform statistical significance testing with `ExtractElementsDistributions.py`.  
5. Export confidence-based CSV files.

---

## ðŸ§  Theoretical Background

HONSigtest is built upon the **Significant Dependencies with Variable Orders Mining (**SDVOM**)** method, designed to enhance the **representability** and **interpretability** of higher-order network (HON) models.

---

## ðŸ“° Publication

This research has been **accepted for publication** in *Chaos, Solitons & Fractals* (Elsevier),  

> **Li, Jiaxu**, Yuan, Xiaoqian, Fu, Yude, Li, Jichao, Tan, Wenhui, and Lu, Xin.  
> *Representing Significant Dependencies with Variable Orders in Networks.*  
> *Chaos, Solitons & Fractals* (2025), in press.  
> DOI â€” forthcoming.

---

## ðŸ“š BibTeX Citation (pre-publication)

---

## ðŸ“„ License

This project is released under the **MIT License**.

---

## ðŸ§± Suggested Repository Additions

To keep your GitHub repository clean, include a `.gitignore` file:

```
__pycache__/
*.pyc
*.pyo
*.pkl
*.pickle
*.npy
*.csv
.idea/
data/
variable/
```

---

### âœ¨ Author

Jiaxu Li, a Ph.D. candidate in Complex Network Science.
Focus: *Higher-Order Network Modeling, and Dependencies with Variable Orders Mining*









